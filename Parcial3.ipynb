{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yulianagalvis/Se-ales-y-sistemas/blob/main/Parcial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARCIAL 3 - SEÑALES Y SISTEMAS\n",
        "\n",
        "## INTEGRANTES: CRISTIAN ARMANDO CHAMORRO MELO - YULIANA ALEXANDRA GALVIS CARDONA - JUAN MANUEL MEJÍA VASCO\n"
      ],
      "metadata": {
        "id": "rjdS1cwe7sQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación de paquetes necesarios para ejecutar"
      ],
      "metadata": {
        "id": "9sySJ91I9hp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sympy --upgrade #actualizar sympy para usar módulo de control\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install streamlit -q #instalación de librerías\n",
        "!pip install soundfile #librerias descarga Youtube y manejo de audios en python\n",
        "!pip install yt-dlp\n",
        "!pip install pydub #instalamos pydub para manipular el audio\n",
        "!pip install scipy\n",
        "!pip install youtube-dl\n",
        "!pip install streamlit pandas numpy matplotlib scikit-learn joblib gdown\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KXaRC8HT6B9",
        "outputId": "9ca47fe3-bf6b-455a-d307-d978f2b0da67",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.13.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
            "    reqs = list(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
            "    cand = self._make_base_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 272, in __init__\n",
            "    cache_entry = factory.get_wheel_cache_entry(source_link, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 611, in get_wheel_cache_entry\n",
            "    supported_tags=get_supported(),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/compatibility_tags.py\", line 142, in get_supported\n",
            "    supported.extend(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/tags.py\", line 224, in cpython_tags\n",
            "    platforms = list(platforms or platform_tags())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/tags.py\", line 499, in _linux_platforms\n",
            "    yield from _manylinux.platform_tags(archs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/_manylinux.py\", line 256, in platform_tags\n",
            "    if _is_compatible(arch, glibc_version):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/_manylinux.py\", line 187, in _is_compatible\n",
            "    import _manylinux\n",
            "  File \"<frozen importlib._bootstrap>\", line 1022, in _find_and_load\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/__main__.py\", line 24, in <module>\n",
            "    sys.exit(_main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 73, in emit\n",
            "    if self.shouldRollover(record):\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 191, in shouldRollover\n",
            "    if os.path.exists(self.baseFilename) and not os.path.isfile(self.baseFilename):\n",
            "  File \"/usr/lib/python3.10/genericpath.py\", line 33, in isfile\n",
            "    return stat.S_ISREG(st.st_mode)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.9.27)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.8.30)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.20.0)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.2.3)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.10/dist-packages (2021.12.17)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Parcial_3.py\n",
        "import streamlit as st\n",
        "\n",
        "# Título de la página\n",
        "st.title('Parcial 3: Señales y Sistemas')\n",
        "\n",
        "# Subtítulo y detalles del curso\n",
        "st.subheader('Profesor: Andrés Marino Álvarez Meza, Ph.D.')\n",
        "st.write('Departamento de Ingeniería Eléctrica, Electrónica, y Computación\\nUniversidad Nacional de Colombia - sede Manizales')\n",
        "\n",
        "# Resumen de los problemas a resolver\n",
        "st.header('Resumen de los Enunciados')\n",
        "\n",
        "# Pregunta 1\n",
        "st.subheader('1. Sistema Masa, Resorte, Amortiguador')\n",
        "st.markdown(\"\"\"\n",
        "- Encontrar la función de transferencia que caracteriza el sistema masa-resorte-amortiguador.\n",
        "- Modelar un sistema equivalente con un circuito RLC.\n",
        "- Presentar un dashboard que permita simular el sistema en diferentes condiciones (subamortiguado, amortiguamiento crítico, sobreamortiguado, etc.).\n",
        "- Incluir gráficas de polos y ceros, diagrama de Bode, respuesta impulso y escalón.\n",
        "\"\"\")\n",
        "\n",
        "# Pregunta 2\n",
        "st.subheader('2. Modulación en Amplitud (AM)')\n",
        "st.markdown(\"\"\"\n",
        "- Encontrar el espectro de la señal modulada en amplitud.\n",
        "- Descargar un fragmento de una canción favorita y simular la modulación AM.\n",
        "- Presentar gráficas de las señales en tiempo y frecuencia.\n",
        "- Implementar una simulación para el proceso de demodulación en amplitud.\n",
        "- Reproducir los fragmentos de audio de mensaje, portadora y señal modulada, e identificar el género musical del audio.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDDThm0q-DZK",
        "outputId": "4e61bc08-e281-4e17-dddc-4dd74db3b77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Parcial_3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear carpeta con los puntos desarrollados"
      ],
      "metadata": {
        "id": "5nIsskdc5zaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear directorio pages\n",
        "import os\n",
        "try:\n",
        "    os.mkdir('pages')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "7mPXl7aVQbjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sistema masa-resorte / circuito RLC\n",
        "\n",
        "Encuentre la función de transferencia que caracteriza el sistema presentado en la Figura (asuma condiciones iniciales cero):\n",
        "\n",
        "![Péndulo Elástico Amortiguado](https://github.com/amalvarezme/SenalesSistemas/blob/master/4_Transformada_Laplace/damped_spring.png?raw=1)\n",
        "\n",
        "Posteriormente, encuentre el sistema equivalente del modelo masa, resorte, amortguador, a partir del siguiente circuito eléctrico:\n",
        "\n",
        "![Circuito RLC](https://github.com/amalvarezme/SenalesSistemas/blob/master/Otros/circuitoRLC.jpeg?raw=1)\n",
        "\n",
        "\n",
        "Luego, encuentre el sistema equivalente a partir de un circuito RLC (entrada de tension - salida tensión del capacitor).\n",
        "Finalmente, desde el modelado desarrollado, presente un\n",
        "dashboard que permita simular el sistema como subamortiguado, con amortiguamiento crítico, sobreamortiguado, oscilatorio e inestable. El usuario podra determinar el valor del\n",
        "factor de amortiguamiento y la simulacion deber  a determi-\n",
        "nar los valores de m, k y c y sus equivalentes R, L y C;\n",
        "ademas de estimar el tipo de amortiguamiento. Asimismo,\n",
        "debera presentar las gráficas de polos y ceros, diagrama de\n",
        "Bode, respuesta impulso y respuesta al escalon. Nota: Para las graficas de Bode, respuesta impulso y respuesta al es-\n",
        "calon, se sugiere utilizar la API de control de Sympy, a partir\n",
        "de los cuadernos guía: Pendulo el  astico y SLIT y fracciones\n",
        "parciales.\n"
      ],
      "metadata": {
        "id": "u8svocqN5qhX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVU0duUGpeid",
        "outputId": "b646bda5-20c5-4fdc-ea3c-9dd514585bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pages/Amortiguador.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile pages/Amortiguador.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sympy as sym\n",
        "from scipy.signal import TransferFunction as tf, bode, impulse, step\n",
        "from sympy.physics.control.lti import TransferFunction\n",
        "from sympy.physics.control.control_plots import pole_zero_plot\n",
        "import warnings\n",
        "\n",
        "# Ignorar advertencias\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Definición de variables simbólicas\n",
        "t, m, c, k, s = sym.symbols('t m c k s', real=True, positive=True)\n",
        "\n",
        "# Título y descripción principal\n",
        "st.title(\"Simulación de Sistema Masa-Resorte-Amortiguador y Clasificación del Tipo de Amortiguamiento\")\n",
        "st.write(\"\"\"\n",
        "Este simulador te permite visualizar cómo funciona un sistema masa-resorte-amortiguador\n",
        "y clasificar el tipo de amortiguamiento en función de los parámetros seleccionados.\n",
        "Puedes modificar los valores de la masa, la constante del resorte y el factor de amortiguamiento (ξ).\n",
        "\"\"\")\n",
        "\n",
        "# Explicación de la fórmula para ξ\n",
        "st.write(\"\"\"\n",
        "El factor de amortiguamiento (ξ) es un parámetro que determina el tipo de amortiguamiento en el sistema.\n",
        "La fórmula que relaciona ξ con la masa (m), la constante del resorte (k), y el coeficiente de amortiguamiento (c) es la siguiente:\n",
        "\"\"\")\n",
        "st.latex(r'\\xi = \\frac{c}{2\\sqrt{k m}}')\n",
        "# Explicación del cálculo de c\n",
        "st.write(\"\"\"\n",
        "El coeficiente de amortiguamiento (c) se calcula usando los valores seleccionados para m, k, y ξ.\n",
        "Este valor influye directamente en el comportamiento del sistema.\n",
        "\"\"\")\n",
        "\n",
        "# Determinación del tipo de amortiguamiento\n",
        "st.write(\"\"\"\n",
        "Dependiendo del valor del factor de amortiguamiento (ξ), el sistema puede estar en uno de los siguientes estados:\n",
        "- **Subamortiguado**: ξ < 1\n",
        "- **Amortiguamiento crítico**: ξ = 1\n",
        "- **Sobreamortiguado**: ξ > 1\n",
        "\"\"\")\n",
        "\n",
        "# Definir la función de transferencia simbólica\n",
        "st.subheader(\"Función de Transferencia\")\n",
        "st.write(\"\"\"\n",
        "La función de transferencia representa la relación entre la salida y la entrada del sistema en el dominio de la frecuencia.\n",
        "Es importante para analizar la estabilidad y el comportamiento dinámico del sistema.\n",
        "\"\"\")\n",
        "\n",
        "# Entrada del usuario: Factor de amortiguamiento\n",
        "xi_val = st.slider(\"Seleccione el valor del Factor de Amortiguamiento (ξ)\", 0.0, 2.0, 0.5)\n",
        "\n",
        "# Definir un rango para `k` y `m` para explorar diferentes combinaciones\n",
        "k_min, k_max = 1.0, 10.0\n",
        "m_min, m_max = 0.5, 5.0\n",
        "# Mostrar sliders para seleccionar los valores de `k` y `m`\n",
        "k_val = st.slider(\"Seleccione un valor para la constante del resorte (k)\", k_min, k_max, 5.0)\n",
        "m_val = st.slider(\"Seleccione un valor para la masa (m)\", m_min, m_max, 1.0)\n",
        "\n",
        "c_val = 2 * xi_val * np.sqrt(k_val * m_val)\n",
        "\n",
        "# Mostrar los valores calculados\n",
        "st.subheader(f\"**Coeficiente de Amortiguamiento (c)**: {c_val:.2f}\")\n",
        "\n",
        "# Mostrar intervalo permitido para cada parámetro que mantenga el tipo de amortiguamiento\n",
        "st.subheader(\"Intervalos permitidos para el mismo tipo de sistema:\")\n",
        "st.write(\"\"\"\n",
        "Aquí se muestran los valores mínimos y máximos del coeficiente de amortiguamiento (c) que mantienen\n",
        "el tipo de amortiguamiento seleccionado.\n",
        "\"\"\")\n",
        "\n",
        "# Calcular los valores mínimos y máximos de c para cada combinación\n",
        "c_min = 2 * 0.01 * np.sqrt(k_val * m_val)  # Mínimo coeficiente de amortiguamiento para ξ = 0.01\n",
        "c_max = 2 * 2.0 * np.sqrt(k_val * m_val)  # Máximo coeficiente de amortiguamiento para ξ = 2.0\n",
        "\n",
        "st.write(f\"**Rango de `c` que preserva el tipo de amortiguamiento**: {c_min:.2f} ≤ c ≤ {c_max:.2f}\")\n",
        "\n",
        "if xi_val < 1:\n",
        "    st.write(\"El sistema está **subamortiguado** (ξ < 1).\")\n",
        "elif xi_val == 1:\n",
        "    st.write(\"El sistema tiene **amortiguamiento crítico** (ξ = 1).\")\n",
        "else:\n",
        "    st.write(\"El sistema está **sobreamortiguado** (ξ > 1).\")\n",
        "\n",
        "H = (1/k_val) * (s**2) / (s**2 + 2 * xi_val * np.sqrt(k_val / m_val) * s + (k_val / m_val))\n",
        "\n",
        "# Crear la función de transferencia usando scipy para simulaciones\n",
        "system = tf([1], [1, 2 * xi_val * np.sqrt(k_val / m_val), k_val / m_val])\n",
        "\n",
        "# Gráfica de polos y ceros con sympy\n",
        "st.subheader(\"Gráfica de Polos y Ceros\")\n",
        "st.write(\"\"\"\n",
        "La gráfica de polos y ceros es fundamental para determinar la estabilidad del sistema.\n",
        "Los polos son los valores donde la salida del sistema tiende al infinito, y los ceros son donde la salida es cero.\n",
        "\"\"\")\n",
        "fig1 = plt.figure()\n",
        "tf1 = TransferFunction(*sym.fraction(H), s)\n",
        "pole_zero_plot(tf1)\n",
        "st.pyplot(fig1)\n",
        "\n",
        "# Diagrama de Bode con scipy\n",
        "st.subheader(\"Diagrama de Bode\")\n",
        "st.write(\"\"\"\n",
        "El diagrama de Bode muestra la respuesta del sistema en términos de magnitud y fase en función de la frecuencia.\n",
        "Es útil para entender cómo el sistema responde a diferentes frecuencias.\n",
        "\"\"\")\n",
        "fig2, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
        "w, mag, phase = bode(system)\n",
        "ax1.semilogx(w, mag)  # Magnitud\n",
        "ax1.set_title('Bode Plot')\n",
        "ax1.set_ylabel('Magnitud (dB)')\n",
        "ax2.semilogx(w, phase)  # Fase\n",
        "ax2.set_ylabel('Fase (grados)')\n",
        "ax2.set_xlabel('Frecuencia (rad/s)')\n",
        "st.pyplot(fig2)\n",
        "\n",
        "# Respuesta al impulso con scipy\n",
        "st.subheader(\"Respuesta al Impulso\")\n",
        "st.write(\"\"\"\n",
        "La respuesta al impulso muestra cómo el sistema responde a una entrada tipo impulso.\n",
        "Es una medida de la estabilidad y rapidez de la respuesta del sistema.\n",
        "\"\"\")\n",
        "t, y_impulse = impulse(system)\n",
        "fig3 = plt.figure()\n",
        "plt.plot(t, y_impulse)\n",
        "plt.title(\"Respuesta al Impulso\")\n",
        "plt.xlabel(\"Tiempo (s)\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "st.pyplot(fig3)\n",
        "\n",
        "# Respuesta al escalón con scipy\n",
        "st.subheader(\"Respuesta al Escalón\")\n",
        "st.write(\"\"\"\n",
        "La respuesta al escalón muestra cómo el sistema responde a una entrada tipo escalón.\n",
        "Es útil para analizar la estabilidad, el sobreimpulso, y el tiempo de asentamiento del sistema.\n",
        "\"\"\")\n",
        "t, y_step = step(system)\n",
        "fig4 = plt.figure()\n",
        "plt.plot(t, y_step)\n",
        "plt.title(\"Respuesta al Escalón\")\n",
        "plt.xlabel(\"Tiempo (s)\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "st.pyplot(fig4)\n",
        "\n",
        "# Conclusión general\n",
        "st.subheader(\"Conclusión General\")\n",
        "st.write(\"\"\"\n",
        "Este simulador de **sistema masa-resorte-amortiguador** proporciona una manera interactiva de visualizar y comprender el comportamiento dinámico de un sistema físico sujeto a fuerzas de amortiguamiento y elasticidad. A través de la variación de parámetros como la masa, la constante del resorte, y el factor de amortiguamiento (ξ), se puede explorar cómo el sistema responde bajo diferentes condiciones, clasificando el tipo de amortiguamiento en tres categorías principales:\n",
        "\n",
        "1. **Subamortiguado (ξ < 1)**: El sistema oscila antes de estabilizarse, con un tiempo de asentamiento más largo y presencia de sobreimpulso.\n",
        "2. **Amortiguamiento crítico (ξ = 1)**: El sistema alcanza la estabilidad sin oscilaciones y en el menor tiempo posible.\n",
        "3. **Sobreamortiguado (ξ > 1)**: El sistema se estabiliza lentamente, sin oscilaciones, pero con un tiempo de respuesta más largo.\n",
        "\n",
        "Además, las herramientas gráficas como los **diagramas de polos y ceros**, **diagramas de Bode**, y las respuestas al **impulso** y **escalón**, permiten un análisis visual del comportamiento del sistema frente a diferentes entradas, proporcionando una mejor comprensión de su estabilidad, tiempo de respuesta y comportamiento en el dominio de la frecuencia.\n",
        "\n",
        "Este enfoque ofrece una manera eficaz de simular el comportamiento de sistemas físicos reales y sugiere aplicaciones útiles en el diseño de sistemas de control en ingeniería, donde la elección adecuada del amortiguamiento es crucial para el rendimiento óptimo.\n",
        "\"\"\")\n",
        "st.write(\"Además recordamos que porlas equivalencias con el sistema RLC-serie:\")\n",
        "st.write(f\"R = {c_val}\")\n",
        "st.write(f\"L = {m_val}\")\n",
        "st.write(f\"C = {1/k_val}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modulación - Demodulación"
      ],
      "metadata": {
        "id": "XC2q2npGiU8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sea la señal portadora c(t) = Ac sin(2πFct), con Ac, Fc ∈ R, y la señal mensaje m(t) ∈ R. Encuentre el espectro en frecuencia de la señal modulada en amplitud (AM), y(t) = (1 + m(t)/Ac) c(t).\n",
        "Luego, descargue desde YouTube 5 segundos de su canción favorita (capturando del segundo 20 al 25). Presente una simulación de modulación por amplitud AM (tomando como mensaje el fragmento de la canción escogida). Grafique las señales en tiempo y frecuencia (magnitud y fase) de la señal mensaje, portadora y modulada. Reproduzca los fragmentos de audio del mensaje, portadora y señal modulada.\n",
        "Nota: se sugiere utilizar un canal de señal de audio para el desarrollo del ejercicio.\n",
        "El usuario debe poder escoger el índice de modulación deseado.\n"
      ],
      "metadata": {
        "id": "4m5pI2V1nTiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sea el demodulador en amplitud presentado en la siguiente figura:\n",
        "\n",
        "![Circuito RLC](https://github.com/amalvarezme/SenalesSistemas/blob/master/Otros/AM.jpeg?raw=1)\n",
        "\n",
        "Asumiendo $\\theta_0 = 0$, presente una simulacion sobre Python\n",
        "para el proceso de demodulacion en amplitud. Especifique\n",
        "adecuadamente las consideraciones de diseño en tiempo y en\n",
        "frecuencia (con las graficas pertinentes), y reproduzca el seg-\n",
        "mento de la cancion para cada una de las etapas del sistema\n",
        "de modulacion y demodulación. Tenga en cuenta el diseño\n",
        "de un filtro digital pasa bajas en la etapa de demodulacion,\n",
        "utilizando Transformada Z. Presente la grafica de polos y\n",
        "ceros y el diagrama de Bode del filtro (se sugiere tener en\n",
        "cuenta el cuaderno Transformada Z).\n",
        "Finalmente, la simulacion tipo dashboard debería también\n",
        "permitir la reproduccion de los fragmentos de audio del mensaje, portadora y senal modulada, y detectar el tipo de género musical del audio empleado. Para ello se deben escoger\n",
        "al menos dos generos musicales en la etapa de entrenamiento del sistema. Nota: se sugiere utilizar un canal de senal de\n",
        "audio para el desarrollo del ejercicio. El usuario debe poder\n",
        "escoger el índice de modulacion deseado"
      ],
      "metadata": {
        "id": "li-87GggnlwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pages/Modulacion.py\n",
        "import streamlit as st\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import subprocess\n",
        "import os\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.signal import butter, filtfilt, freqz_zpk\n",
        "from pydub import AudioSegment\n",
        "from yt_dlp import YoutubeDL\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "# Función para descargar audio de YouTube y convertirlo a WAV\n",
        "def descargar_audio_youtube(url):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio[ext=m4a]',\n",
        "        'outtmpl': 'audio.m4a'\n",
        "    }\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "    audio = AudioSegment.from_file(\"audio.m4a\", format=\"m4a\")\n",
        "    audio.export(\"audio.wav\", format=\"wav\")\n",
        "\n",
        "# Función para graficar la respuesta de frecuencia de un filtro digital\n",
        "def plot_freq_response(filter_name, w, h, N):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.set_title(filter_name + '.' + str(N))\n",
        "    ax1.plot(w, 20 * np.log10(abs(h)), 'b')\n",
        "    ax1.set_ylabel('Amplitud [dB]', color='b')\n",
        "    ax1.set_xlabel('Frecuencia[Hz]')\n",
        "    ax1.grid()\n",
        "    ax2 = ax1.twinx()\n",
        "    angles = np.unwrap(np.angle(h))\n",
        "    ax2.plot(w, angles, 'g')\n",
        "    ax2.set_ylabel('Ángulo [radianes]', color='g')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Función para mostrar polos y ceros en el plano Z\n",
        "def show_zp(z, p, title='Plano Z'):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(np.real(z), np.imag(z), 'bo', fillstyle='none', ms=10)\n",
        "    ax.plot(np.real(p), np.imag(p), 'rx', fillstyle='none', ms=10)\n",
        "    unit_circle = Circle((0, 0), radius=1, fill=False, color='black', ls='solid', alpha=0.9)\n",
        "    ax.add_patch(unit_circle)\n",
        "    ax.axvline(0, color='0.7')\n",
        "    ax.axhline(0, color='0.7')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(r'Re{$z$}')\n",
        "    ax.set_ylabel(r'Im{$z$}')\n",
        "    ax.axis('equal')\n",
        "    ax.set_xlim((-2, 2))\n",
        "    ax.set_ylim((-2, 2))\n",
        "    ax.grid()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Título de la aplicación\n",
        "st.title('Simulación de Modulación AM y Demodulación')\n",
        "\n",
        "# Input para el enlace de YouTube\n",
        "url = st.text_input('Ingrese el enlace de YouTube de la canción que desea procesar')\n",
        "\n",
        "# Descargar y convertir el audio si se proporciona un enlace\n",
        "try:\n",
        "  os.remove(\"audio.m4a\")\n",
        "  os.remove(\"audio.wav\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if url:\n",
        "    with st.spinner('Descargando y procesando el audio...'):\n",
        "        descargar_audio_youtube(url)\n",
        "        st.success('Descarga y conversión completa.')\n",
        "\n",
        "    st.markdown(\"### Procesamiento de la Señal Original\")\n",
        "    st.write(\"En este paso se descarga el audio desde YouTube y se convierte en un archivo WAV para su procesamiento posterior.\")\n",
        "\n",
        "    # Cargar archivo WAV\n",
        "\n",
        "    audio_file = \"audio.wav\"\n",
        "    xa, fs = sf.read(audio_file)\n",
        "    st.write(f\"Frecuencia de muestreo: {fs} Hz\")\n",
        "\n",
        "    # Extraer segmento de audio\n",
        "    ti = 20  # Tiempo inicial en segundos\n",
        "    tf = 25  # Tiempo final en segundos\n",
        "    m = xa[int(ti*fs):int(tf*fs), 0]\n",
        "    tt = np.arange(0, len(m)) / fs\n",
        "\n",
        "    st.markdown(\"### Visualización de la Señal en el Tiempo\")\n",
        "    st.write(\"Graficamos la señal de audio en función del tiempo para observar su forma de onda y analizarla visualmente.\")\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(tt, m)\n",
        "    ax.set_xlabel('Tiempo [s]')\n",
        "    ax.set_ylabel('Amplitud')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Reproducir señal original\n",
        "    wav_buffer = io.BytesIO()\n",
        "    sf.write(wav_buffer, m, fs, format='wav')\n",
        "    wav_buffer.seek(0)\n",
        "    st.audio(wav_buffer, format='audio/wav')\n",
        "\n",
        "    st.markdown(\"### Espectro de la Señal Original\")\n",
        "    st.write(\"A través de la transformada de Fourier, convertimos la señal original al dominio de la frecuencia para ver su distribución espectral.\")\n",
        "    Mw = np.fft.rfft(m)\n",
        "    vf = np.fft.rfftfreq(m.shape[0], 1/fs)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(vf, np.abs(Mw))\n",
        "    ax.set_title('Magnitud del espectro')\n",
        "    ax.set_xlabel('Frecuencia [Hz]')\n",
        "    ax.set_ylabel('|M(f)|')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    st.markdown(\"### Generación de la Portadora\")\n",
        "    st.write(\"Definimos una frecuencia para la portadora, la cual es una señal sinusoidal que usaremos para modular la señal original.\")\n",
        "    Fo = st.number_input('Frecuencia de la portadora (Hz)', min_value=1000, max_value=50000, value=15000)\n",
        "    c = np.cos(2 * np.pi * Fo * tt)\n",
        "\n",
        "     # Reproducir señal portadora\n",
        "    wav_buffer = io.BytesIO()\n",
        "    sf.write(wav_buffer, c, fs, format='wav')\n",
        "    wav_buffer.seek(0)\n",
        "    st.audio(wav_buffer, format='audio/wav')\n",
        "\n",
        "    st.markdown(\"### Modulación AM\")\n",
        "    st.write(\"Aplicamos modulación en amplitud (AM) multiplicando la señal original por la portadora.\")\n",
        "    # Selección del índice de modulación\n",
        "    mu = st.slider('Índice de modulación (μ)', min_value=0.0, max_value=2.0, value=1.0, step=0.1)\n",
        "    A1 = 2  # Amplitud de la portadora\n",
        "    y = (1 + mu * m) * c\n",
        "\n",
        "    # Graficar señal modulada\n",
        "    st.subheader('Señal modulada AM en el tiempo')\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(tt, y)\n",
        "    ax.set_xlabel('Tiempo [s]')\n",
        "    ax.set_ylabel('Amplitud')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    #Reproducir Señal modulada\n",
        "    wav_buffer = io.BytesIO()\n",
        "    sf.write(wav_buffer, y, fs, format='wav')\n",
        "    wav_buffer.seek(0)\n",
        "    st.audio(wav_buffer, format='audio/wav')\n",
        "\n",
        "    st.markdown(\"### Demodulación\")\n",
        "    st.write(\"Multiplicamos la señal modulada por la misma portadora para recuperar la señal original, que queda 'envuelta' en la portadora.\")\n",
        "    d = y * c  # Señal demodulada\n",
        "\n",
        "    # Reproducir señal demodulada\n",
        "    wav_buffer = io.BytesIO()\n",
        "    sf.write(wav_buffer, d, fs, format='wav')\n",
        "    wav_buffer.seek(0)\n",
        "    st.audio(wav_buffer, format='audio/wav')\n",
        "\n",
        "    # Graficar señal demodulada\n",
        "    st.subheader('Señal demodulada en el tiempo')\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(tt, d)\n",
        "    ax.set_xlabel('Tiempo [s]')\n",
        "    ax.set_ylabel('Amplitud')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    st.markdown(\"### Filtrado de la Señal Demodulada\")\n",
        "    st.write(\"Se utiliza un filtro pasa-bajas para eliminar la portadora y recuperar la señal de mensaje original.\")\n",
        "    # Filtro pasa-bajas\n",
        "    N = 10\n",
        "    Wn = 14950  # Frecuencia de corte\n",
        "    zeros, poles, gain = butter(N, Wn, btype='low', output='zpk', fs=fs)\n",
        "    w, h = freqz_zpk(zeros, poles, gain, fs=fs)\n",
        "\n",
        "    # Graficar respuesta del filtro\n",
        "    plot_freq_response('Filtro Butterworth', w, h, N)\n",
        "\n",
        "    # Graficar polos y ceros\n",
        "    show_zp(zeros, poles)\n",
        "\n",
        "    # Filtrar señal demodulada\n",
        "    num, den = butter(N, Wn, btype='low', fs=fs)\n",
        "    xf = filtfilt(num, den, d)\n",
        "    me = (2 / A1) * xf  # Señal recuperada\n",
        "\n",
        "    st.markdown(\"### Resultados Finales\")\n",
        "    st.write(\"Finalmente, se reproduce y se grafica la señal recuperada.\")\n",
        "    wav_buffer = io.BytesIO()\n",
        "    sf.write(wav_buffer, me, fs, format='wav')\n",
        "    wav_buffer.seek(0)\n",
        "    st.audio(wav_buffer, format='audio/wav')\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(tt, me)\n",
        "    ax.set_xlabel('Tiempo [s]')\n",
        "    ax.set_ylabel('Amplitud')\n",
        "    st.pyplot(fig)\n",
        "\n"
      ],
      "metadata": {
        "id": "clwQl2gR1gEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2682e973-ae02-4de1-f645-4d4dfd230c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pages/Modulacion.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detector"
      ],
      "metadata": {
        "id": "JuWbpkcuNU6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pages/Detector.py\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "import yt_dlp as youtube_dl\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import math\n",
        "import io\n",
        "\n",
        "# Configuración inicial\n",
        "st.title(\"Clasificador de Canciones: Bachata vs Metal\")\n",
        "# Explicación del modelo\n",
        "st.markdown(\"\"\"\n",
        "### Teoría de Clasificación de Géneros Musicales con Machine Learning\n",
        "En el campo de la **clasificación de audio**, el objetivo es identificar automáticamente el género de una canción basándose en características extraídas de la señal. Para esto, se construyen modelos de machine learning que analizan patrones en el dominio de las **frecuencias** y el **tiempo** para diferenciar entre distintas categorías musicales.\n",
        "\"\"\")\n",
        "model_path = \"bachata_vs_metal.pkl\"\n",
        "\n",
        "# Cargar el modelo cada vez que se proporciona un nuevo link\n",
        "@st.cache_data\n",
        "def cargar_modelo():\n",
        "    return joblib.load(model_path)\n",
        "\n",
        "# Función para descargar el archivo MP3 desde YouTube\n",
        "def download_ytvid_as_mp3(video_url, name):\n",
        "  \"\"\"\n",
        "  Utiliza la librería `yt_dlp` para descargar solo el audio de un video de YouTube.\n",
        "  Esto se hace porque los modelos de análisis de audio requieren el formato WAV para una mayor precisión.\n",
        "  \"\"\"\n",
        "  video_info = youtube_dl.YoutubeDL().extract_info(url=video_url, download=False)\n",
        "  filename = f\"{name}.mp3\"\n",
        "  options = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'keepvideo': False,\n",
        "      'outtmpl': filename,\n",
        "  }\n",
        "  with youtube_dl.YoutubeDL(options) as ydl:\n",
        "      ydl.download([video_info['webpage_url']])\n",
        "\n",
        "  return filename\n",
        "\n",
        "# Input del usuario\n",
        "video_url = st.text_input(\"Ingrese el link de YouTube para la canción:\")\n",
        "if video_url:\n",
        "  # Inicializar variables\n",
        "  my_model_loaded = cargar_modelo()  # Cargar el modelo desde el archivo cada vez\n",
        "  name_ = 'results/Nueva_cancion'\n",
        "\n",
        "  # Descargar y convertir la canción\n",
        "  if not os.path.exists('results'):\n",
        "      os.mkdir('results')\n",
        "  try:\n",
        "    os.remove('results/Nueva_cancion.mp3')\n",
        "\n",
        "    os.remove('results/Nueva_cancion.wav')\n",
        "  except FileNotFoundError:\n",
        "    pass\n",
        "  download_ytvid_as_mp3(video_url, name_)\n",
        "  subprocess.call(['ffmpeg', '-y', '-i', name_+'.mp3', name_+'.wav'])\n",
        "\n",
        "  # Leer el archivo WAV\n",
        "  st.markdown(\"\"\"### Extracción de características de audio\n",
        "  La señal de audio es una función del tiempo que contiene información acerca de la **amplitud** y **frecuencia** de la onda sonora. Para analizar la estructura de la música, primero segmentamos el archivo en fragmentos más pequeños. De esta manera, podemos capturar cambios locales en el espectro que son indicativos del estilo musical.\n",
        "  \"\"\")\n",
        "  fs = 48000\n",
        "  tl = np.array([40, 50, 60, 70, 80, 90, 100])  # puntos de lectura\n",
        "  ts = 5  # tiempo segmento\n",
        "  Ns = 7  # cantidad segmentos\n",
        "  x_t = np.zeros((Ns, int(ts*fs), 2))  # Ns segmentos, cantidad de muestras, 2 canales (stereo)\n",
        "\n",
        "  x, fs = sf.read(name_+'.wav')\n",
        "  for i, ti in enumerate(tl):  # segmentar la canción\n",
        "      x_t[i] = x[int(fs*ti):int(fs*(ti+ts)), :]\n",
        "\n",
        "  # Reproducir segmento de la canción\n",
        "  wav_buffer = io.BytesIO()\n",
        "  sf.write(wav_buffer, x_t[1], fs, format='wav')\n",
        "  wav_buffer.seek(0)\n",
        "  st.audio(wav_buffer, format='audio/wav')\n",
        "\n",
        "\n",
        "  # Aplicación de la Transformada de Fourier\n",
        "  st.markdown(\"\"\"\n",
        "  ### Análisis de la Transformada de Fourier\n",
        "  La **Transformada de Fourier** permite descomponer la señal de audio en sus componentes de frecuencia. Esto es crucial en la clasificación de géneros, ya que ciertos estilos musicales (como el Metal) contienen patrones específicos en las bandas de frecuencia altas, mientras que la Bachata tiende a mostrar patrones en bandas de frecuencia más bajas.\n",
        "\n",
        "  Mediante la **Transformada Rápida de Fourier (FFT)**, calculamos la representación espectral de cada segmento. La frecuencia se representa en el eje horizontal y la magnitud (potencia) en el eje vertical.\n",
        "  \"\"\")\n",
        "  vf = np.fft.rfftfreq(x_t.shape[1], 1/fs)  # vector de frecuencias\n",
        "  Xw = np.fft.rfft(x_t, axis=1).mean(axis=-1)  # transformada rápida de Fourier\n",
        "\n",
        "  # Graficar señales de tiempo y frecuencia\n",
        "  st.markdown(\"\"\"\n",
        "  ### Señal de audio en el tiempo\n",
        "  \"\"\"\n",
        "  )\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(np.arange(0, ts, 1/fs), x_t.mean(axis=-1).T)\n",
        "  ax.set_xlabel('t [s]')\n",
        "  ax.set_ylabel('x(t)')\n",
        "  st.pyplot(fig)\n",
        "\n",
        "  # Graficar la transformada de Fourier\n",
        "  st.markdown(\"\"\"\n",
        "  ### Transformada de Fourier\n",
        "  \"\"\"\n",
        "  )\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(vf, abs(Xw).T)\n",
        "  ax.set_xlabel('f [Hz]')\n",
        "  ax.set_ylabel('|X(f)|')\n",
        "  st.pyplot(fig)\n",
        "\n",
        "  # Normalización de las características espectrales\n",
        "  st.markdown(\"\"\"\n",
        "  ### Normalización de características\n",
        "  Para que los modelos de machine learning puedan comparar diferentes muestras de audio, es importante que todas las características tengan el mismo rango. Aquí utilizamos la técnica de **normalización Min-Max**, que ajusta los valores entre 0 y 1.\n",
        "  \"\"\")\n",
        "  sca = MinMaxScaler()\n",
        "  Xw_ = sca.fit_transform(abs(Xw).T).T\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(vf, Xw_.T)\n",
        "  ax.set_xlabel('f [Hz]')\n",
        "  ax.set_ylabel('|X(f)| (Normalizado)')\n",
        "  st.pyplot(fig)\n",
        "\n",
        "  # Agregar fragmentos al modelo\n",
        "  my_model_loaded['Xw_'] = np.concatenate([my_model_loaded['Xw_'], Xw_], axis=0)\n",
        "  label = np.ones((7, 1)) * 1.5\n",
        "  my_model_loaded['label'] = np.concatenate([my_model_loaded['label'], label], axis=0)\n",
        "  name_c = [\"Nueva_cancion_0\" for i in range(7)]\n",
        "  my_model_loaded['name_c'].extend(name_c)\n",
        "\n",
        "  # Reducción de dimensionalidad con TSNE\n",
        "  st.markdown(\"\"\"\n",
        "  ### Reducción de dimensionalidad con TSNE\n",
        "  Los datos de audio tienen un alto número de dimensiones debido a la cantidad de frecuencias analizadas. Para visualizar las relaciones entre canciones, utilizamos **TSNE (T-Distributed Stochastic Neighbor Embedding)**, una técnica de reducción de dimensionalidad que proyecta los puntos en un espacio 2D preservando relaciones de proximidad.\n",
        "  \"\"\")\n",
        "  red_ = TSNE(perplexity=30, n_components=2, random_state=0, learning_rate='auto', init='pca')\n",
        "  X_2D = red_.fit_transform(my_model_loaded['Xw_'][:, :my_model_loaded['fmax']])\n",
        "\n",
        "  # Ubicar puntos cercanos\n",
        "  vpos = []\n",
        "  for i in X_2D[-7:]:\n",
        "    menor = 10000000\n",
        "    pos = 0\n",
        "    for countj, j in enumerate(X_2D[:-7]):\n",
        "      dist = math.dist(i, j)\n",
        "      if dist < menor:\n",
        "        menor = dist\n",
        "        pos = countj\n",
        "    vpos.append(pos)\n",
        "\n",
        "  # Graficar puntos 2D\n",
        "  fig, ax = plt.subplots()\n",
        "  scatter = ax.scatter(X_2D[:, 0], X_2D[:, 1], c=my_model_loaded['label'], s=10)\n",
        "  for i in vpos:\n",
        "      ax.scatter(X_2D[i, 0], X_2D[i, 1], c='r', marker='x')\n",
        "  fig.colorbar(scatter)\n",
        "  st.pyplot(fig)\n",
        "\n",
        "  # Clasificación según puntos cercanos\n",
        "  st.markdown(\"\"\"\n",
        "  ### Clasificación de la canción\n",
        "  La clasificación se realiza determinando las etiquetas de los puntos más cercanos a los nuevos segmentos. Si la mayoría de los puntos cercanos pertenecen a \"Metal\", la canción es clasificada como Metal; de lo contrario, es clasificada como Bachata.\n",
        "  \"\"\")\n",
        "  nmetal = sum(my_model_loaded['label'][i] == 1.0 for i in vpos)\n",
        "  nbachata = len(vpos) - nmetal\n",
        "\n",
        "  if nmetal > nbachata:\n",
        "      st.write(\"La canción seleccionada es Metal 🎸\")\n",
        "  else:\n",
        "      st.write(\"La canción seleccionada es Bachata 💃\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZIMksxQ3uug",
        "outputId": "3f3db669-dc6a-4ef8-e901-0fef94fe45f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pages/Detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenador"
      ],
      "metadata": {
        "id": "y2SGq3jAntSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%writefile pages/Entrenador.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess\n",
        "import yt_dlp as youtube_dl\n",
        "import soundfile as sf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import joblib\n",
        "import gdown\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "# Configuración de la página\n",
        "st.set_page_config(\n",
        "    page_title=\"Análisis de Género Musical\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "st.title(\"Análisis de Género Musical con Streamlit\")\n",
        "\n",
        "# 1. Descarga de Datos desde Google Drive\n",
        "st.header(\"1. Descarga de Datos desde Google Drive\")\n",
        "\n",
        "FILEID = \"1DudgUNAZPWv_42o9iOEAKurQQlnuCPNL\"\n",
        "DOWNLOAD_URL = f\"https://drive.google.com/uc?id={FILEID}&export=download\"\n",
        "\n",
        "output = \"canciones.xlsx\"\n",
        "\n",
        "if not os.path.exists(output):\n",
        "    with st.spinner(\"Descargando archivo de Google Drive...\"):\n",
        "        try:\n",
        "            gdown.download(DOWNLOAD_URL, output, quiet=False)\n",
        "            st.success(\"Archivo descargado exitosamente.\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error al descargar el archivo: {e}\")\n",
        "else:\n",
        "    st.info(\"El archivo 'canciones.xlsx' ya existe.\")\n",
        "\n",
        "# 2. Visualización de los Datos\n",
        "st.header(\"2. Visualización de los Datos\")\n",
        "\n",
        "try:\n",
        "    X = pd.read_excel(output)\n",
        "    st.write(\"Vista previa de los datos:\")\n",
        "    st.dataframe(X.head())\n",
        "except Exception as e:\n",
        "    st.error(f\"Error al leer el archivo Excel: {e}\")\n",
        "\n",
        "# 3. Descarga y Procesamiento de Audios de YouTube\n",
        "st.header(\"3. Descarga y Procesamiento de Audios de YouTube\")\n",
        "\n",
        "# Instalación de yt-dlp y soundfile (Si no están instalados)\n",
        "# Nota: Streamlit puede reiniciar la aplicación después de una instalación, lo que puede interrumpir el flujo.\n",
        "# Es recomendable instalar las dependencias antes de ejecutar la aplicación.\n",
        "\n",
        "# Definir funciones necesarias\n",
        "@st.cache_data\n",
        "def download_ytvid_as_mp3(video_url, name):\n",
        "    video_info = youtube_dl.YoutubeDL().extract_info(url=video_url, download=False)\n",
        "    filename = f\"{name}.mp3\"\n",
        "    options = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'keepvideo': False,\n",
        "        'outtmpl': filename,\n",
        "    }\n",
        "\n",
        "    with youtube_dl.YoutubeDL(options) as ydl:\n",
        "        ydl.download([video_info['webpage_url']])\n",
        "\n",
        "    return filename\n",
        "\n",
        "# Crear carpeta para resultados\n",
        "results_dir = 'results'\n",
        "if not os.path.exists(results_dir):\n",
        "    os.mkdir(results_dir)\n",
        "    st.info(f\"Carpeta '{results_dir}' creada.\")\n",
        "else:\n",
        "    st.info(f\"Carpeta '{results_dir}' ya existe.\")\n",
        "\n",
        "# Botón para iniciar el proceso de descarga y procesamiento\n",
        "if st.button(\"Iniciar Descarga y Procesamiento de Audios\"):\n",
        "    N, P = X.shape\n",
        "    Ns = N * 5  # Cantidad de segmentos por canción\n",
        "\n",
        "    progress_bar = st.progress(0)\n",
        "    status_text = st.empty()\n",
        "\n",
        "    for n in range(N):\n",
        "        status_text.text(f\"Procesando video {n+1} de {N}\")\n",
        "        st.write(f\"**Link:** {X.loc[n, 'link']}\")\n",
        "        st.write(f\"**Artista:** {X.loc[n, 'artista']}\")\n",
        "        st.write(f\"**Género:** {X.loc[n, 'genero']}\")\n",
        "\n",
        "        # Ruta video n-ésimo\n",
        "        name_ = f\"{results_dir}/{X.loc[n, 'artista']}_{n}_{X.loc[n,'tipo']}\"\n",
        "\n",
        "        try:\n",
        "            # Descargar mp3 desde YouTube\n",
        "            download_ytvid_as_mp3(X.loc[n, 'link'], name_)\n",
        "            st.success(f\"Descargado: {name_}.mp3\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error al descargar el video {n+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Convertir a .wav usando ffmpeg\n",
        "            subprocess.call(['ffmpeg', '-y', '-i', f\"{name_}.mp3\", f\"{name_}.wav\"], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "            st.success(f\"Convertido a WAV: {name_}.wav\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error al convertir a WAV para el video {n+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "        progress_bar.progress((n + 1) / N)\n",
        "\n",
        "    st.success(\"Descarga y conversión de audios completadas.\")\n",
        "\n",
        "# 4. Procesamiento de Audio y Extracción de Características\n",
        "st.header(\"4. Procesamiento de Audio y Extracción de Características\")\n",
        "\n",
        "if st.button(\"Procesar Audios y Extraer Características\"):\n",
        "    path = 'results/'\n",
        "    wav_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "    st.write(f\"Archivos WAV encontrados: {len(wav_files)}\")\n",
        "\n",
        "    if len(wav_files) == 0:\n",
        "        st.warning(\"No se encontraron archivos WAV para procesar.\")\n",
        "    else:\n",
        "        # Parámetros de procesamiento\n",
        "        fs = 48000\n",
        "        tl = np.array([40,50,60,70,80,90,100])  # Puntos de lectura\n",
        "        ts = 5  # Duración del segmento en segundos\n",
        "        Ns = len(wav_files) * len(tl)  # Cantidad de segmentos\n",
        "        x_t = np.zeros((Ns, int(ts * fs), 2))  # Stereo\n",
        "        label = np.zeros((Ns, 1))  # Género\n",
        "        name_c = []\n",
        "\n",
        "        i = 0\n",
        "        progress_bar = st.progress(0)\n",
        "        status_text = st.empty()\n",
        "\n",
        "        for name in wav_files:\n",
        "            status_text.text(f\"Procesando archivo: {name}\")\n",
        "            try:\n",
        "                x, fs = sf.read(os.path.join(path, name))\n",
        "                audio_duration = len(x) / fs\n",
        "\n",
        "                for ti in tl:\n",
        "                    if ti + ts <= audio_duration:\n",
        "                        x_t[i] = x[int(fs * ti):int(fs * (ti + ts)), :2]  # Asegurarse de tener 2 canales\n",
        "                        label[i] = int(name[-5])  # Suponiendo que el tipo de género está en el nombre del archivo\n",
        "                        name_c.append(name[:-6])\n",
        "                        i += 1\n",
        "                    else:\n",
        "                        st.warning(f\"Omitiendo segmento para {name} en {ti} segundos.\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error al procesar {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "            progress_bar.progress((i) / Ns)\n",
        "\n",
        "        x_t = x_t[:i]\n",
        "        label = label[:i]\n",
        "        name_c = name_c[:i]\n",
        "\n",
        "        st.success(\"Procesamiento de audios completado.\")\n",
        "        st.write(f\"Forma de x_t: {x_t.shape}\")\n",
        "        st.write(f\"Forma de label: {label.shape}\")\n",
        "\n",
        "        # Guardar variables para uso posterior\n",
        "        model_data = {\n",
        "            'x_t': x_t,\n",
        "            'fs': fs,\n",
        "            'label': label,\n",
        "            'name_c': name_c\n",
        "        }\n",
        "\n",
        "        st.session_state['model_data'] = model_data\n",
        "\n",
        "# 5. Visualización de Resultados\n",
        "st.header(\"5. Visualización de Resultados\")\n",
        "\n",
        "if 'model_data' in st.session_state:\n",
        "    model_data = st.session_state['model_data']\n",
        "    x_t = model_data['x_t']\n",
        "    fs = model_data['fs']\n",
        "    label = model_data['label']\n",
        "    name_c = model_data['name_c']\n",
        "\n",
        "    st.subheader(\"Reproducir un Segmento de Audio\")\n",
        "    i = st.slider(\"Selecciona el segmento a reproducir\", 0, len(x_t)-1, 0)\n",
        "    st.audio(x_t[i].T, format='audio/wav', sample_rate=fs)\n",
        "\n",
        "    st.subheader(\"Cálculo de la Transformada de Fourier\")\n",
        "    vf = np.fft.rfftfreq(x_t.shape[1], 1/fs)\n",
        "    Xw = np.fft.rfft(x_t, axis=1).mean(axis=-1)\n",
        "\n",
        "    st.write(f\"Forma de Xw: {Xw.shape}\")\n",
        "\n",
        "    st.subheader(\"Gráficas de Tiempo y Fourier\")\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    ax1.plot(np.arange(0, ts, 1/fs), x_t[i].mean(axis=-1).T)\n",
        "    ax1.set_xlabel('t [s]')\n",
        "    ax1.set_ylabel('x(t)')\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    fig2, ax2 = plt.subplots()\n",
        "    ax2.plot(vf, np.abs(Xw[i]).T)\n",
        "    ax2.set_xlabel('f [Hz]')\n",
        "    ax2.set_ylabel('|X(f)|')\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    # Normalización de espectros\n",
        "    sca = MinMaxScaler()\n",
        "    Xw_ = sca.fit_transform(np.abs(Xw).T).T\n",
        "\n",
        "    fig3, ax3 = plt.subplots()\n",
        "    ax3.plot(vf, Xw_.T)\n",
        "    ax3.set_xlabel('f [Hz]')\n",
        "    ax3.set_ylabel('|X(f)| (Normalizado)')\n",
        "    st.pyplot(fig3)\n",
        "\n",
        "    # En dB\n",
        "    fig4, ax4 = plt.subplots()\n",
        "    ax4.plot(vf, (20 * np.log10(Xw_ + 1e-10)).T)\n",
        "    ax4.set_xlabel('f [Hz]')\n",
        "    ax4.set_ylabel('|X(f)| dB')\n",
        "    st.pyplot(fig4)\n",
        "\n",
        "    # Reducción de Dimensionalidad\n",
        "    st.subheader(\"Reducción de Dimensionalidad con t-SNE\")\n",
        "\n",
        "    fmax = 7000\n",
        "    X_reduced = TSNE(n_components=2, random_state=123, perplexity=20, learning_rate='auto').fit_transform(Xw_[:, :fmax])\n",
        "\n",
        "    fig5, ax5 = plt.subplots()\n",
        "    scatter = ax5.scatter(X_reduced[:, 0], X_reduced[:, 1], c=label.squeeze(), cmap='viridis', s=10)\n",
        "    plt.colorbar(scatter, ax=ax5, label='Género')\n",
        "    ax5.set_title(\"Visualización 2D de los Segmentos de Audio\")\n",
        "    st.pyplot(fig5)\n",
        "\n",
        "    st.success(\"Visualización completada.\")\n",
        "else:\n",
        "    st.warning(\"Por favor, procesa los audios antes de visualizar los resultados.\")\n",
        "\n",
        "# 6. Guardar y Descargar el Modelo\n",
        "st.header(\"6. Guardar y Descargar el Modelo\")\n",
        "\n",
        "if 'model_data' in st.session_state and st.button(\"Guardar Modelo\"):\n",
        "    model_data = st.session_state['model_data']\n",
        "    x_t = model_data['x_t']\n",
        "    fs = model_data['fs']\n",
        "    label = model_data['label']\n",
        "    name_c = model_data['name_c']\n",
        "\n",
        "    try:\n",
        "        # Crear carpeta para el modelo\n",
        "        modelo_dir = 'modelo'\n",
        "        if not os.path.exists(modelo_dir):\n",
        "            os.mkdir(modelo_dir)\n",
        "\n",
        "        # Guardar el modelo\n",
        "        filename_ = os.path.join(modelo_dir, 'Bachata_vs_metal.pkl')\n",
        "        model_ = {\n",
        "            'Xw_': x_t,  # Deberías ajustar esto según lo que realmente quieres guardar\n",
        "            'fmax': fmax,\n",
        "            'label': label,\n",
        "            'name_c': name_c,\n",
        "            'vf': vf,\n",
        "            'fs': fs\n",
        "        }\n",
        "        joblib.dump(model_, filename_)\n",
        "        st.success(\"Modelo guardado exitosamente.\")\n",
        "\n",
        "        # Comprimir la carpeta del modelo\n",
        "        namefile = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '_modelo'\n",
        "        shutil.make_archive(namefile, 'zip', modelo_dir)\n",
        "\n",
        "        # Descargar el archivo comprimido\n",
        "        with open(f\"{namefile}.zip\", \"rb\") as fp:\n",
        "            btn = st.download_button(\n",
        "                label=\"Descargar Modelo\",\n",
        "                data=fp,\n",
        "                file_name=f\"{namefile}.zip\",\n",
        "                mime=\"application/zip\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al guardar el modelo: {e}\")\n",
        "\n",
        "else:\n",
        "    st.warning(\"Aún no hay datos para guardar el modelo.\")\"\"\""
      ],
      "metadata": {
        "id": "y-3js35FJ1K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fee655-23c0-41a3-8187-928f403742fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%%writefile pages/Entrenador.py\\nimport streamlit as st\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport os\\nimport subprocess\\nimport yt_dlp as youtube_dl\\nimport soundfile as sf\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.manifold import TSNE\\nfrom sklearn.decomposition import PCA\\nimport joblib\\nimport gdown\\nfrom datetime import datetime\\nimport shutil\\n\\n# Configuración de la página\\nst.set_page_config(\\n    page_title=\"Análisis de Género Musical\",\\n    layout=\"wide\",\\n    initial_sidebar_state=\"expanded\",\\n)\\n\\nst.title(\"Análisis de Género Musical con Streamlit\")\\n\\n# 1. Descarga de Datos desde Google Drive\\nst.header(\"1. Descarga de Datos desde Google Drive\")\\n\\nFILEID = \"1DudgUNAZPWv_42o9iOEAKurQQlnuCPNL\"\\nDOWNLOAD_URL = f\"https://drive.google.com/uc?id={FILEID}&export=download\"\\n\\noutput = \"canciones.xlsx\"\\n\\nif not os.path.exists(output):\\n    with st.spinner(\"Descargando archivo de Google Drive...\"):\\n        try:\\n            gdown.download(DOWNLOAD_URL, output, quiet=False)\\n            st.success(\"Archivo descargado exitosamente.\")\\n        except Exception as e:\\n            st.error(f\"Error al descargar el archivo: {e}\")\\nelse:\\n    st.info(\"El archivo \\'canciones.xlsx\\' ya existe.\")\\n\\n# 2. Visualización de los Datos\\nst.header(\"2. Visualización de los Datos\")\\n\\ntry:\\n    X = pd.read_excel(output)\\n    st.write(\"Vista previa de los datos:\")\\n    st.dataframe(X.head())\\nexcept Exception as e:\\n    st.error(f\"Error al leer el archivo Excel: {e}\")\\n\\n# 3. Descarga y Procesamiento de Audios de YouTube\\nst.header(\"3. Descarga y Procesamiento de Audios de YouTube\")\\n\\n# Instalación de yt-dlp y soundfile (Si no están instalados)\\n# Nota: Streamlit puede reiniciar la aplicación después de una instalación, lo que puede interrumpir el flujo.\\n# Es recomendable instalar las dependencias antes de ejecutar la aplicación.\\n\\n# Definir funciones necesarias\\n@st.cache_data\\ndef download_ytvid_as_mp3(video_url, name):\\n    video_info = youtube_dl.YoutubeDL().extract_info(url=video_url, download=False)\\n    filename = f\"{name}.mp3\"\\n    options = {\\n        \\'format\\': \\'bestaudio/best\\',\\n        \\'keepvideo\\': False,\\n        \\'outtmpl\\': filename,\\n    }\\n\\n    with youtube_dl.YoutubeDL(options) as ydl:\\n        ydl.download([video_info[\\'webpage_url\\']])\\n\\n    return filename\\n\\n# Crear carpeta para resultados\\nresults_dir = \\'results\\'\\nif not os.path.exists(results_dir):\\n    os.mkdir(results_dir)\\n    st.info(f\"Carpeta \\'{results_dir}\\' creada.\")\\nelse:\\n    st.info(f\"Carpeta \\'{results_dir}\\' ya existe.\")\\n\\n# Botón para iniciar el proceso de descarga y procesamiento\\nif st.button(\"Iniciar Descarga y Procesamiento de Audios\"):\\n    N, P = X.shape\\n    Ns = N * 5  # Cantidad de segmentos por canción\\n\\n    progress_bar = st.progress(0)\\n    status_text = st.empty()\\n\\n    for n in range(N):\\n        status_text.text(f\"Procesando video {n+1} de {N}\")\\n        st.write(f\"**Link:** {X.loc[n, \\'link\\']}\")\\n        st.write(f\"**Artista:** {X.loc[n, \\'artista\\']}\")\\n        st.write(f\"**Género:** {X.loc[n, \\'genero\\']}\")\\n\\n        # Ruta video n-ésimo\\n        name_ = f\"{results_dir}/{X.loc[n, \\'artista\\']}_{n}_{X.loc[n,\\'tipo\\']}\"\\n\\n        try:\\n            # Descargar mp3 desde YouTube\\n            download_ytvid_as_mp3(X.loc[n, \\'link\\'], name_)\\n            st.success(f\"Descargado: {name_}.mp3\")\\n        except Exception as e:\\n            st.error(f\"Error al descargar el video {n+1}: {e}\")\\n            continue\\n\\n        try:\\n            # Convertir a .wav usando ffmpeg\\n            subprocess.call([\\'ffmpeg\\', \\'-y\\', \\'-i\\', f\"{name_}.mp3\", f\"{name_}.wav\"], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\\n            st.success(f\"Convertido a WAV: {name_}.wav\")\\n        except Exception as e:\\n            st.error(f\"Error al convertir a WAV para el video {n+1}: {e}\")\\n            continue\\n\\n        progress_bar.progress((n + 1) / N)\\n\\n    st.success(\"Descarga y conversión de audios completadas.\")\\n\\n# 4. Procesamiento de Audio y Extracción de Características\\nst.header(\"4. Procesamiento de Audio y Extracción de Características\")\\n\\nif st.button(\"Procesar Audios y Extraer Características\"):\\n    path = \\'results/\\'\\n    wav_files = [f for f in os.listdir(path) if f.endswith(\\'.wav\\')]\\n    st.write(f\"Archivos WAV encontrados: {len(wav_files)}\")\\n\\n    if len(wav_files) == 0:\\n        st.warning(\"No se encontraron archivos WAV para procesar.\")\\n    else:\\n        # Parámetros de procesamiento\\n        fs = 48000\\n        tl = np.array([40,50,60,70,80,90,100])  # Puntos de lectura\\n        ts = 5  # Duración del segmento en segundos\\n        Ns = len(wav_files) * len(tl)  # Cantidad de segmentos\\n        x_t = np.zeros((Ns, int(ts * fs), 2))  # Stereo\\n        label = np.zeros((Ns, 1))  # Género\\n        name_c = []\\n\\n        i = 0\\n        progress_bar = st.progress(0)\\n        status_text = st.empty()\\n\\n        for name in wav_files:\\n            status_text.text(f\"Procesando archivo: {name}\")\\n            try:\\n                x, fs = sf.read(os.path.join(path, name))\\n                audio_duration = len(x) / fs\\n\\n                for ti in tl:\\n                    if ti + ts <= audio_duration:\\n                        x_t[i] = x[int(fs * ti):int(fs * (ti + ts)), :2]  # Asegurarse de tener 2 canales\\n                        label[i] = int(name[-5])  # Suponiendo que el tipo de género está en el nombre del archivo\\n                        name_c.append(name[:-6])\\n                        i += 1\\n                    else:\\n                        st.warning(f\"Omitiendo segmento para {name} en {ti} segundos.\")\\n            except Exception as e:\\n                st.error(f\"Error al procesar {name}: {e}\")\\n                continue\\n\\n            progress_bar.progress((i) / Ns)\\n\\n        x_t = x_t[:i]\\n        label = label[:i]\\n        name_c = name_c[:i]\\n\\n        st.success(\"Procesamiento de audios completado.\")\\n        st.write(f\"Forma de x_t: {x_t.shape}\")\\n        st.write(f\"Forma de label: {label.shape}\")\\n\\n        # Guardar variables para uso posterior\\n        model_data = {\\n            \\'x_t\\': x_t,\\n            \\'fs\\': fs,\\n            \\'label\\': label,\\n            \\'name_c\\': name_c\\n        }\\n\\n        st.session_state[\\'model_data\\'] = model_data\\n\\n# 5. Visualización de Resultados\\nst.header(\"5. Visualización de Resultados\")\\n\\nif \\'model_data\\' in st.session_state:\\n    model_data = st.session_state[\\'model_data\\']\\n    x_t = model_data[\\'x_t\\']\\n    fs = model_data[\\'fs\\']\\n    label = model_data[\\'label\\']\\n    name_c = model_data[\\'name_c\\']\\n\\n    st.subheader(\"Reproducir un Segmento de Audio\")\\n    i = st.slider(\"Selecciona el segmento a reproducir\", 0, len(x_t)-1, 0)\\n    st.audio(x_t[i].T, format=\\'audio/wav\\', sample_rate=fs)\\n\\n    st.subheader(\"Cálculo de la Transformada de Fourier\")\\n    vf = np.fft.rfftfreq(x_t.shape[1], 1/fs)\\n    Xw = np.fft.rfft(x_t, axis=1).mean(axis=-1)\\n\\n    st.write(f\"Forma de Xw: {Xw.shape}\")\\n\\n    st.subheader(\"Gráficas de Tiempo y Fourier\")\\n    fig1, ax1 = plt.subplots()\\n    ax1.plot(np.arange(0, ts, 1/fs), x_t[i].mean(axis=-1).T)\\n    ax1.set_xlabel(\\'t [s]\\')\\n    ax1.set_ylabel(\\'x(t)\\')\\n    st.pyplot(fig1)\\n\\n    fig2, ax2 = plt.subplots()\\n    ax2.plot(vf, np.abs(Xw[i]).T)\\n    ax2.set_xlabel(\\'f [Hz]\\')\\n    ax2.set_ylabel(\\'|X(f)|\\')\\n    st.pyplot(fig2)\\n\\n    # Normalización de espectros\\n    sca = MinMaxScaler()\\n    Xw_ = sca.fit_transform(np.abs(Xw).T).T\\n\\n    fig3, ax3 = plt.subplots()\\n    ax3.plot(vf, Xw_.T)\\n    ax3.set_xlabel(\\'f [Hz]\\')\\n    ax3.set_ylabel(\\'|X(f)| (Normalizado)\\')\\n    st.pyplot(fig3)\\n\\n    # En dB\\n    fig4, ax4 = plt.subplots()\\n    ax4.plot(vf, (20 * np.log10(Xw_ + 1e-10)).T)\\n    ax4.set_xlabel(\\'f [Hz]\\')\\n    ax4.set_ylabel(\\'|X(f)| dB\\')\\n    st.pyplot(fig4)\\n\\n    # Reducción de Dimensionalidad\\n    st.subheader(\"Reducción de Dimensionalidad con t-SNE\")\\n\\n    fmax = 7000\\n    X_reduced = TSNE(n_components=2, random_state=123, perplexity=20, learning_rate=\\'auto\\').fit_transform(Xw_[:, :fmax])\\n\\n    fig5, ax5 = plt.subplots()\\n    scatter = ax5.scatter(X_reduced[:, 0], X_reduced[:, 1], c=label.squeeze(), cmap=\\'viridis\\', s=10)\\n    plt.colorbar(scatter, ax=ax5, label=\\'Género\\')\\n    ax5.set_title(\"Visualización 2D de los Segmentos de Audio\")\\n    st.pyplot(fig5)\\n\\n    st.success(\"Visualización completada.\")\\nelse:\\n    st.warning(\"Por favor, procesa los audios antes de visualizar los resultados.\")\\n\\n# 6. Guardar y Descargar el Modelo\\nst.header(\"6. Guardar y Descargar el Modelo\")\\n\\nif \\'model_data\\' in st.session_state and st.button(\"Guardar Modelo\"):\\n    model_data = st.session_state[\\'model_data\\']\\n    x_t = model_data[\\'x_t\\']\\n    fs = model_data[\\'fs\\']\\n    label = model_data[\\'label\\']\\n    name_c = model_data[\\'name_c\\']\\n\\n    try:\\n        # Crear carpeta para el modelo\\n        modelo_dir = \\'modelo\\'\\n        if not os.path.exists(modelo_dir):\\n            os.mkdir(modelo_dir)\\n\\n        # Guardar el modelo\\n        filename_ = os.path.join(modelo_dir, \\'Bachata_vs_metal.pkl\\')\\n        model_ = {\\n            \\'Xw_\\': x_t,  # Deberías ajustar esto según lo que realmente quieres guardar\\n            \\'fmax\\': fmax,\\n            \\'label\\': label,\\n            \\'name_c\\': name_c,\\n            \\'vf\\': vf,\\n            \\'fs\\': fs\\n        }\\n        joblib.dump(model_, filename_)\\n        st.success(\"Modelo guardado exitosamente.\")\\n\\n        # Comprimir la carpeta del modelo\\n        namefile = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + \\'_modelo\\'\\n        shutil.make_archive(namefile, \\'zip\\', modelo_dir)\\n\\n        # Descargar el archivo comprimido\\n        with open(f\"{namefile}.zip\", \"rb\") as fp:\\n            btn = st.download_button(\\n                label=\"Descargar Modelo\",\\n                data=fp,\\n                file_name=f\"{namefile}.zip\",\\n                mime=\"application/zip\"\\n            )\\n    except Exception as e:\\n        st.error(f\"Error al guardar el modelo: {e}\")\\n\\nelse:\\n    st.warning(\"Aún no hay datos para guardar el modelo.\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexión a Ngrok"
      ],
      "metadata": {
        "id": "fcOzWDY7fLST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cambiar su token\n",
        "usuario=\"Juan\"\n",
        "if usuario==\"Yuliana\":\n",
        "  token = '2lLjHoDPtNqGFhA3XCMXaV7TSzC_2WMetgXt54NgDAv4qBuZE' #colocar aquí su token personal después de crear su cuenta con correo UNAL en Ngrok\n",
        "elif usuario==\"Juan\":\n",
        "  token = '2lLkHdYMBU6KwzPcVAaxaNJyYYj_5y1Y8DSwG18FHt3fkdFzX'\n",
        "elif usuario=='Cristian':\n",
        "  token = '2lLjBy3NA0GhfCDLgRI47jQwMpL_4FDAUMmnURPshTKsBFXY8'"
      ],
      "metadata": {
        "id": "Te7ZMDcppspR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set authentication token (unique per user)\n",
        "ngrok.set_auth_token(token)\n",
        "\n",
        "# Start Streamlit server on a specific port\n",
        "!nohup streamlit run Parcial_3.py --server.port 8730 & #cambiar el puerto 8499 pueden poner cualquier número de 4 digitos\n",
        "\n",
        "# Start ngrok tunnel to expose the Streamlit server\n",
        "ngrok_tunnel = ngrok.connect(addr='8730', proto='http', bind_tls=True) #acá tambien lo tienen que cambiar\n",
        "\n",
        "# Print the URL of the ngrok tunnel\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "zAEjslWd2YyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40866dab-a4b4-4780-f7ab-dfa380285551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            " * Tunnel URL: https://7c24-35-199-56-91.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Función para listar los túneles activos de ngrok\n",
        "def listar_tuneles_ngrok():\n",
        "    tuneles = subprocess.check_output([\"ngrok\", \"tunnels\"], text=True)\n",
        "    print(\"Túneles activos:\\n\", tuneles)\n",
        "\n",
        "# Función para cerrar un túnel específico\n",
        "def cerrar_tunel_ngrok(tunnel_name):\n",
        "    comando_cerrar = f\"ngrok http -stop={tunnel_name}\"\n",
        "    os.system(comando_cerrar)\n",
        "    print(f\"Túnel {tunnel_name} cerrado.\")\n",
        "\n",
        "# Función para detener todos los túneles\n",
        "def detener_ngrok():\n",
        "    os.system(\"pkill ngrok\")\n",
        "    print(\"Todos los túneles de ngrok han sido detenidos.\")\n",
        "\n",
        "# Mostrar túneles activos\n",
        "listar_tuneles_ngrok()\n",
        "\n",
        "# Cerrar un túnel específico (reemplaza el ID del túnel por el tuyo)\n",
        "cerrar_tunel_ngrok(\"tn_2mnPKN0oQEkgkKjXq5H7Tk5J6Xr\")\n",
        "\n",
        "# Detener todos los túneles (opción alternativa)\n",
        "detener_ngrok()"
      ],
      "metadata": {
        "id": "BYkgpErUhZyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b8d5ca-2eb0-4529-eef4-1e84f7f1992c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Túneles activos:\n",
            " \n",
            "Túnel tn_2mnPKN0oQEkgkKjXq5H7Tk5J6Xr cerrado.\n",
            "Todos los túneles de ngrok han sido detenidos.\n"
          ]
        }
      ]
    }
  ]
}